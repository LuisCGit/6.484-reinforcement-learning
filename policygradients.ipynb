{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisCGit/6.484-reinforcement-learning/blob/main/policygradients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AGouWesMiIR"
      },
      "source": [
        "# Spring 2022 6.884 Computational Sensorimotor Learning Assignment 2\n",
        "\n",
        "In this assignment, we will implement model-free RL algorithms from scratch to solve `DoorKeyEnv5x5`.  We will cover:\n",
        "\n",
        "\n",
        "* REINFORCE\n",
        "* Vanilla Policy Gradient (VPG)\n",
        "* Generalized Advantage Estimation (GAE)\n",
        "* Proximal Policy Optimization (PPO)\n",
        "\n",
        "You will need to **answer the bolded questions** and **fill in the missing code snippets** (marked by **TODO**).\n",
        "\n",
        "There are (approximately) **150** total points to be had in this PSET.  `ctrl-f` for \"pts\" to ensure you don't miss questions.\n",
        "\n",
        "**_Please fill in your name below:_**\n",
        "\n",
        "**Name**: Luis Costa Laveron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRdsOe1INwSL"
      },
      "source": [
        "## Setup\n",
        "\n",
        "The following code sets up requirements, imports, and helper functions (you can ignore this)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jX9eHiRsbDdX"
      },
      "outputs": [],
      "source": [
        "!pip install gym-minigrid &>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oZDM2oukbDdc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "import torch.nn.functional as F\n",
        "import gym_minigrid\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from tqdm.notebook import tqdm\n",
        "from gym_minigrid.envs.doorkey import DoorKeyEnv\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P6yYDc3bN6DU"
      },
      "outputs": [],
      "source": [
        "# Function from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr/blob/master/model.py\n",
        "def init_params(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Linear\") != -1:\n",
        "        m.weight.data.normal_(0, 1)\n",
        "        m.weight.data *= 1 / torch.sqrt(m.weight.data.pow(2).sum(1, keepdim=True))\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0)\n",
        "\n",
        "def preprocess_obss(obss, device=None):\n",
        "    if isinstance(obss, dict):\n",
        "        images = np.array([obss[\"image\"]])\n",
        "    else:\n",
        "        images = np.array([o[\"image\"] for o in obss])\n",
        "    \n",
        "    return torch.tensor(images, device=device, dtype=torch.float)\n",
        "\n",
        "class DoorKeyEnv5x5(DoorKeyEnv):\n",
        "    def __init__(self):\n",
        "        super().__init__(size=5)\n",
        "    \n",
        "    def _reward(self):\n",
        "        \"\"\"\n",
        "        Compute the reward to be given upon success\n",
        "        \"\"\"\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dl6tYW2aJ3Ji"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self,\n",
        "                score_threshold=0.93,\n",
        "                discount=0.995,\n",
        "                lr=1e-3,\n",
        "                max_grad_norm=0.5,\n",
        "                log_interval=10,\n",
        "                max_episodes=2000,\n",
        "                gae_lambda=0.95,\n",
        "                use_critic=False,\n",
        "                clip_ratio=0.2,\n",
        "                target_kl=0.01,\n",
        "                train_ac_iters=5,\n",
        "                use_discounted_reward=False,\n",
        "                entropy_coef=0.01,\n",
        "                use_gae=False):\n",
        "        \n",
        "        self.score_threshold = score_threshold\n",
        "        self.discount = discount\n",
        "        self.lr = lr\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.log_interval = log_interval\n",
        "        self.max_episodes = max_episodes\n",
        "        self.use_critic = use_critic\n",
        "        self.clip_ratio = clip_ratio\n",
        "        self.target_kl = target_kl\n",
        "        self.train_ac_iters = train_ac_iters\n",
        "        self.gae_lambda=gae_lambda\n",
        "        self.use_discounted_reward=use_discounted_reward\n",
        "        self.entropy_coef = entropy_coef\n",
        "        self.use_gae = use_gae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98WOwXCKP54C"
      },
      "source": [
        "# Task (Environment)\n",
        "\n",
        "In this assignment, we will work with the `DoorKeyEnv5x5` environment from [gym_miniworld](https://github.com/maximecb/gym-minigrid). This environment is a $5\\times 5$ gridworld. The agent needs to pick up the key, open the door, and then go the the green cell. The agent gets a $+1$ reward if it reaches the green cell, and a $0$ reward otherwise.\n",
        "\n",
        "The environment is visually shown below:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CvgnCnitP54D"
      },
      "outputs": [],
      "source": [
        "env = DoorKeyEnv5x5()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD17fnXWP54D"
      },
      "source": [
        "**Question**: What does `env.reset()` return? What does each item returned mean? What's the shape of the image in the observation? How about the action space? What does each action mean? (Hint: You may find the source code of gym_minigrid helpful.) (10 pts)\n",
        "\n",
        "**Answer**: `env.reset()` resets the state of the grid world and returns a first observation. The observation comes in the form of a dictionary with the following items:\n",
        "\n",
        "*   'direction' : the agent's direction/orientation (acting as a compass). This is an integer, where 0 is facing right, 1 is down, 2 is left and 3 is up.\n",
        "*   'image' : a partially observable view of the environment. It is a 3D array with dimensions for width, height and channels (the channels have type, color and state information)\n",
        "*   'mission' : a textual mission string (instructions for the agent)\n",
        "\n",
        "* There are 7 available actions to the agent:\n",
        "  * 0 : turn left\n",
        "  * 1 : turn right\n",
        "  * 2 : move forward \n",
        "  * 3 : pick up an object \n",
        "  * 4 : drop an object \n",
        "  * 5 : toggle/activate an object \n",
        "  * 6 : done completing task \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBTY5ky9N8uC"
      },
      "source": [
        "# Model\n",
        "\n",
        "In policy gradients, we will directly learn a policy: i.e, for each state, predict an action!  We call this policy network the *actor*.\n",
        "\n",
        "Our *actor* will take in as input the `DoorKeyEnv5x5` observation (a 7x7x3 image), and output a [Categorical distribution](https://pytorch.org/docs/stable/distributions.html#categorical) over all possible actions.  To choose an action, we will sample from this distribution.  We suggest implementing the actor network to contain a few convolutional layers followed by a few fully-connected layers.\n",
        "\n",
        "In addition to the actor network, later questions in the PSET require estimating the value network, called the *critic*.  The critic estimates total future reward, much like DQN will in a future problem set, but is notably *on-policy*, meaning it's reward estimates are conditioned on the actor. We will use the critic to reduce variance in the policy gradient estimate. \n",
        "\n",
        "For now, fill in the **TODOS** to implement the actor-critic model below.  We suggest having separate actor and critic networks, as this has been shown to empirically improve performance.\n",
        "\n",
        "As this will have to be correct for your policy gradients algorithms to work, we will not grade this code independently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fTpcS-cYbDdd"
      },
      "outputs": [],
      "source": [
        "# class ACModel(nn.Module):\n",
        "#     def __init__(self, num_actions, use_critic=False):\n",
        "#         super().__init__()\n",
        "#         self.use_critic = use_critic\n",
        "#         self.num_actions = num_actions\n",
        "\n",
        "#         ##### TODO: initialize actor and critic networks #######\n",
        "#         self.layer_dict_actor = nn.ModuleDict()  \n",
        "\n",
        "#         # Define actor's model\n",
        "#         num_filters = 32\n",
        "#         kernel_size = 3\n",
        "#         out = torch.zeros((1,3,7,7)) # create dummy inputs to be used to infer shapes of layers\n",
        "#         self.layer_dict_actor['convolution_1'] = nn.Conv2d(in_channels=out.shape[1], out_channels=num_filters,\n",
        "#                                                           kernel_size=kernel_size, stride=1)\n",
        "#         out = self.layer_dict_actor['convolution_1'].forward(out)\n",
        "#         #self.layer_dict_actor['batchnorm_1'] = nn.BatchNorm2d(num_features=out.shape[1])\n",
        "#         #out = F.leaky_relu(self.layer_dict_actor['batchnorm_1'].forward(out))\n",
        "#         self.layer_dict_actor['convolution_2'] = nn.Conv2d(in_channels=out.shape[1], out_channels=num_filters,\n",
        "#                                                           kernel_size=kernel_size, stride=1)\n",
        "#         out = self.layer_dict_actor['convolution_2'].forward(out)\n",
        "#         # self.layer_dict_actor['batchnorm_2'] = nn.BatchNorm2d(num_features=out.shape[1])\n",
        "#         # out = F.leaky_relu(self.layer_dict_actor['batchnorm_2'].forward(out))\n",
        "\n",
        "#         out = out.view(out.shape[0], -1)  # flatten outputs from (b, c, h, w) to (b, c*h*w)\n",
        "#         self.layer_dict_actor['fully_connected'] = nn.Linear(in_features=out.shape[1],  # initialize the prediction output linear layer\n",
        "#                                       out_features=self.num_actions)\n",
        "#         out = self.layer_dict_actor['fully_connected'].forward(out)\n",
        "\n",
        "#         # Define critic's model\n",
        "#         if self.use_critic:\n",
        "#           pass\n",
        "#         else:\n",
        "#           self.layer_dict_critic = nn.ModuleDict()\n",
        "\n",
        "#         ########################################################\n",
        "\n",
        "#         # Initialize parameters correctly (don't remove this!)\n",
        "#         self.apply(init_params)\n",
        "\n",
        "#     def forward(self, obs):\n",
        "#         conv_in = obs.transpose(1, 3).transpose(2, 3) # reshape into expected order\n",
        "#         dist, value = None, None\n",
        "#         ##### TODO: produce Categorical action distribtuion and critic value output #####\n",
        "#         ##### if self.use_critic is false, return all zeros for value ###################\n",
        "#         out = self.layer_dict_actor['convolution_1'].forward(conv_in)\n",
        "#         #out = F.leaky_relu(self.layer_dict_actor['batchnorm_1'].forward(out))\n",
        "#         out = F.relu(out)\n",
        "#         out = self.layer_dict_actor['convolution_2'].forward(out)\n",
        "#         out = F.relu(out)\n",
        "#         out = out.view(out.shape[0], -1)  # flatten outputs from (b, c, h, w) to (b, c*h*w)\n",
        "#         #out = F.leaky_relu(self.layer_dict_actor['batchnorm_2'].forward(out))\n",
        "#         out = self.layer_dict_actor['fully_connected'].forward(out)\n",
        "#         probs = F.softmax(out,dim=1)\n",
        "#         dist = torch.distributions.categorical.Categorical(probs=probs)\n",
        "#         if self.use_critic:\n",
        "#           pass\n",
        "#         else:\n",
        "#           value = 0\n",
        "#         ##################################################################################\n",
        "\n",
        "#         return dist, value\n",
        "\n",
        "class ACModel(nn.Module):\n",
        "    def __init__(self, num_actions, use_critic=False):\n",
        "        super().__init__()\n",
        "        self.use_critic = use_critic\n",
        "\n",
        "        # Define actor's model\n",
        "        self.image_conv_actor = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, (2, 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            nn.Conv2d(16, 32, (2, 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, (2, 2)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(64, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, num_actions)\n",
        "        )\n",
        "\n",
        "        # Define critic's model\n",
        "        if self.use_critic:\n",
        "            self.image_conv_critic = nn.Sequential(\n",
        "                nn.Conv2d(3, 16, (2, 2)),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d((2, 2)),\n",
        "                nn.Conv2d(16, 32, (2, 2)),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 64, (2, 2)),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "            self.critic = nn.Sequential(\n",
        "                nn.Linear(64, 64),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(64, 1)\n",
        "            )\n",
        "\n",
        "        # Initialize parameters correctly\n",
        "        self.apply(init_params)\n",
        "\n",
        "    def forward(self, obs):\n",
        "        conv_in = obs.transpose(1, 3).transpose(2, 3) # reshape into expected order\n",
        "\n",
        "        dist, value = None, None\n",
        "\n",
        "        x = self.image_conv_actor(conv_in)\n",
        "        embedding = x.reshape(x.shape[0], -1)\n",
        "\n",
        "        x = self.actor(embedding)\n",
        "        dist = Categorical(logits=F.log_softmax(x, dim=1))\n",
        "\n",
        "        if self.use_critic:\n",
        "            y = self.image_conv_critic(conv_in)\n",
        "            embedding = y.reshape(y.shape[0], -1)\n",
        "\n",
        "            value = self.critic(embedding).squeeze(1)\n",
        "        else:\n",
        "            value = torch.zeros((x.shape[0], 1), device=x.device)\n",
        "\n",
        "        return dist, value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9mwBFZ3RowL"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "The following code runs the actor critic model `acmodel` for one episode, and returns a dictionary with all the relevant information from the rollout.  It relies on placeholders below for `compute_advantage_gae` and `compute_discounted_return`: you can ignore these for now, and just evaluate through to the next section.  However, it might be useful to review this code just to make sure you understand what's going on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "d-Wv0yZDR-cZ"
      },
      "outputs": [],
      "source": [
        "def compute_advantage_gae(values, rewards, T, gae_lambda, discount):\n",
        "    advantages = torch.zeros_like(values)\n",
        "\n",
        "    #### TODO: populate GAE in advantages over T timesteps (10 pts) ############\n",
        "    # print(\"advantages shape\", advantages.shape)\n",
        "    # print(\"gae_lambda: \", gae_lambda)\n",
        "    # print(\"T: \", T)\n",
        "    # N = len(rewards)\n",
        "    # for t in range(N):\n",
        "    #   total = 0 \n",
        "    #   for k in range(1,T+1):\n",
        "    #     R = rewards[t] + sum([rewards[i]*discount**(i-t) for i in range(t+1,t+k)])\n",
        "    #     R += values[t+k]*discount**(k)\n",
        "    #     total += gae_lambda*R\n",
        "\n",
        "    #   advantages[t] = R - values[t]\n",
        "    ############################################################################\n",
        "    \n",
        "    return advantages[:T]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "67XzIFyRSARg"
      },
      "outputs": [],
      "source": [
        "def compute_discounted_return(rewards, discount, device=None):\n",
        "    returns = torch.zeros(*rewards.shape, device=device)\n",
        "\n",
        "    #### TODO: populate discounted reward trajectory (10 pts) ############\n",
        "    T = len(rewards)\n",
        "    for t in range(T-1):\n",
        "      returns[t] = sum([(discount**(i-(t+1)))*rewards[i] for i in range(t,T)])\n",
        "\n",
        "    returns = []\n",
        "    for t in range(len(rewards)):\n",
        "        Gt = 0 \n",
        "        pw = 0\n",
        "        for r in rewards[t:]:\n",
        "            Gt = Gt + discount**pw * r\n",
        "            pw = pw + 1\n",
        "        returns.append(Gt)\n",
        "        \n",
        "    returns = torch.tensor(returns)\n",
        "    ######################################################################\n",
        "    return returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ekC6vsRzbDdd"
      },
      "outputs": [],
      "source": [
        "def collect_experiences(env, acmodel, args, device=None):\n",
        "    \"\"\"Collects rollouts and computes advantages.\n",
        "    Returns\n",
        "    -------\n",
        "    exps : dict\n",
        "        Contains actions, rewards, advantages etc as attributes.\n",
        "        Each attribute, e.g. `exps['reward']` has a shape\n",
        "        (self.num_frames, ...).\n",
        "    logs : dict\n",
        "        Useful stats about the training process, including the average\n",
        "        reward, policy loss, value loss, etc.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    MAX_FRAMES_PER_EP = 300\n",
        "    shape = (MAX_FRAMES_PER_EP, )\n",
        "\n",
        "    actions = torch.zeros(*shape, device=device, dtype=torch.int)\n",
        "    values = torch.zeros(*shape, device=device)\n",
        "    rewards = torch.zeros(*shape, device=device)\n",
        "    log_probs = torch.zeros(*shape, device=device)\n",
        "    obss = [None]*MAX_FRAMES_PER_EP\n",
        "\n",
        "    obs = env.reset()\n",
        "\n",
        "    total_return = 0\n",
        "\n",
        "    T = 0\n",
        "\n",
        "    while True:\n",
        "        # Do one agent-environment interaction\n",
        "\n",
        "        preprocessed_obs = preprocess_obss(obs, device=device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            dist, value = acmodel(preprocessed_obs)\n",
        "        action = dist.sample()[0]\n",
        "\n",
        "\n",
        "        obss[T] = obs\n",
        "        obs, reward, done, _ = env.step(action.item())\n",
        "\n",
        "\n",
        "        # Update experiences values\n",
        "        #print()\n",
        "        actions[T] = action\n",
        "        values[T] = value\n",
        "        rewards[T] = reward\n",
        "        log_probs[T] = dist.log_prob(action)\n",
        "\n",
        "\n",
        "        total_return += reward\n",
        "        T += 1\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    discounted_reward = compute_discounted_return(rewards[:T], args.discount, device)\n",
        "    exps = dict(\n",
        "        obs = preprocess_obss([\n",
        "            obss[i]\n",
        "            for i in range(T)\n",
        "        ], device=device),\n",
        "        action = actions[:T],\n",
        "        value  = values[:T],\n",
        "        reward = rewards[:T],\n",
        "        advantage = discounted_reward-values[:T],\n",
        "        log_prob = log_probs[:T],\n",
        "        discounted_reward = discounted_reward,\n",
        "        advantage_gae=compute_advantage_gae(values, rewards, T, args.gae_lambda, args.discount)\n",
        "    )\n",
        "\n",
        "    logs = {\n",
        "        \"return_per_episode\": total_return,\n",
        "        \"num_frames\": T\n",
        "    }\n",
        "\n",
        "    return exps, logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfKUViEGbDde"
      },
      "source": [
        "# REINFORCE\n",
        "\n",
        "Now comes the fun part!  Using the `collect_experiences` function and `ACModel`, we will implement vanilla policy gradients.  The following function takes in an `optimizer`, `ACModel`, batch of experience `sb`, and some arguments `args` (see `Config` in setup for fields and default values), and should perform a policy gradients parameter update using the observed experience.\n",
        "\n",
        "Fill in todos below to implement vanilla policy gradients (20 pts)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "bzrKmjywSE0H"
      },
      "outputs": [],
      "source": [
        "def update_parameters_reinforce(optimizer, acmodel, sb, args):\n",
        "    def _compute_policy_loss(logps, returns):\n",
        "        policy_loss = torch.tensor(0)\n",
        "\n",
        "        #### TODO: complete policy loss (10 pts) ###\n",
        "        # print(\"logps : \", logps)\n",
        "        # print(\"returns: \", returns)\n",
        "        policy_loss = (logps*returns).sum()*-1 #-1 for gradient ascent?\n",
        "        ############################################\n",
        "\n",
        "        return policy_loss\n",
        "\n",
        "\n",
        "    logps, reward = None, None\n",
        "    \n",
        "    ### TODO: compute logps and reward from acmodel, sb['obs'], sb['action'], and sb['reward'] ###\n",
        "    ### If args.use_discounted_reward is True, use sb['discounted_reward'] instead. ##############\n",
        "    ### (10 pts) #########################################\n",
        "    dist, value = acmodel.forward(sb['obs'])\n",
        "    actions = sb['action']\n",
        "    logps = dist.logits\n",
        "    logps = logps.gather(1, actions.long().unsqueeze(1)).reshape(-1)\n",
        "    if args.use_discounted_reward:\n",
        "      reward = sb['discounted_reward']\n",
        "      print(\"discounted reward: \", reward)\n",
        "    else:\n",
        "      reward = sb['reward']\n",
        "      reward = torch.flip(torch.cumsum(torch.flip(reward,dims=[0]),dim=0),dims=[0])\n",
        "      print(\"normal reward: \", reward)\n",
        "\n",
        "    #reward = np.cumsum(reward[::-1])[::-1] \n",
        "    ##############################################################################################\n",
        "\n",
        "    policy_loss = _compute_policy_loss(logps, reward)\n",
        "    update_policy_loss = policy_loss.item()\n",
        "\n",
        "    # Update actor-critic\n",
        "    optimizer.zero_grad()\n",
        "    policy_loss.backward()\n",
        "    \n",
        "    # Perform gradient clipping for stability\n",
        "    for p in acmodel.parameters():\n",
        "        if p.grad is None:\n",
        "            print(\"Make sure you're not instantiating any critic variables when the critic is not used\")\n",
        "    update_grad_norm = sum(p.grad.data.norm(2) ** 2 for p in acmodel.parameters()) ** 0.5\n",
        "    torch.nn.utils.clip_grad_norm_(acmodel.parameters(), args.max_grad_norm)\n",
        "    optimizer.step()\n",
        "\n",
        "    # Log some values\n",
        "    logs = {\n",
        "        \"policy_loss\": update_policy_loss,\n",
        "        \"grad_norm\": update_grad_norm\n",
        "    }\n",
        "\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC--D8zMVBtW"
      },
      "source": [
        "Now, let's try to run our implementation.  The following experiment harness is written for you, and will run sequential episodes of policy gradients until `args.max_episodes` timesteps are exceeded or the rolling average reward (over the last 100 episodes is greater than `args.score_threshold`. It is expected to get highly variable results, and we'll visualize some of this variability at the end.\n",
        "\n",
        "The method accepts as arguments a `Config` object `args`, and a `parameter_update` method (such as `update_parameters_reinforce`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "HiPziB2AbDdf"
      },
      "outputs": [],
      "source": [
        "def run_experiment(args, parameter_update):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    env = DoorKeyEnv5x5()\n",
        "\n",
        "    acmodel = ACModel(env.action_space.n, use_critic=args.use_critic)\n",
        "    acmodel.to(device)\n",
        "\n",
        "    is_solved = False\n",
        "    \n",
        "    SMOOTH_REWARD_WINDOW = 50\n",
        "\n",
        "    pd_logs, rewards = [], [0]*SMOOTH_REWARD_WINDOW\n",
        "    \n",
        "    optimizer = torch.optim.Adam(acmodel.parameters(), lr=args.lr)\n",
        "    num_frames = 0\n",
        "\n",
        "    pbar = tqdm(range(args.max_episodes))\n",
        "    for update in pbar:\n",
        "        exps, logs1 = collect_experiences(env, acmodel, args, device)\n",
        "        logs2 = parameter_update(optimizer, acmodel, exps, args)\n",
        "\n",
        "        logs = {**logs1, **logs2}\n",
        "\n",
        "        num_frames += logs[\"num_frames\"]\n",
        "        \n",
        "        rewards.append(logs[\"return_per_episode\"])\n",
        "        \n",
        "        smooth_reward = np.mean(rewards[-SMOOTH_REWARD_WINDOW:])\n",
        "\n",
        "        data = {'episode':update, 'num_frames':num_frames, 'smooth_reward':smooth_reward,\n",
        "                'reward':logs[\"return_per_episode\"], 'policy_loss':logs[\"policy_loss\"]}\n",
        "        \n",
        "        if args.use_critic:\n",
        "            data['value_loss'] = logs[\"value_loss\"]\n",
        "\n",
        "        pd_logs.append(data)\n",
        "\n",
        "        pbar.set_postfix(data)\n",
        "\n",
        "        # Early terminate\n",
        "        if smooth_reward >= args.score_threshold:\n",
        "            is_solved = True\n",
        "            break\n",
        "\n",
        "    if is_solved:\n",
        "        print('Solved!')\n",
        "    \n",
        "    return pd.DataFrame(pd_logs).set_index('episode')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt63uqbfVmxl"
      },
      "source": [
        "## Run Reinforce\n",
        "\n",
        "Great!  Now let's run our implementation, and see how we do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "mPxIilNE4NXf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "32d70935683b4b70ba52ce4d8c4ecf31",
            "ba4adfef044e4cbb9f9a743b86c596ac",
            "cc28ede2352e4a0989d740aeb9a57ba9",
            "984bc6afff304445a5a3c1047e9104af",
            "e03872966c434462861b46c3b29393a2",
            "26f74b809e254d02a380a3c94c7b24fa",
            "b53b994be6b342ccaac24cadbd274e6c",
            "1a8f4f5a33564cb5b5de647df27da9e5",
            "de4f8894d42548fdae361e0f9e574369",
            "e46cce569d5647cdb6e0c7b9eb7f1e62",
            "ba875c6c447446c695b15cb23f5378ea"
          ]
        },
        "outputId": "de5cf2ed-c88b-4f3f-c022-dbb02b0166e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32d70935683b4b70ba52ce4d8c4ecf31",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "normal reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-f7f779ad14f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#args.max_episodes = args.max_episodes // 2 #delete later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_parameters_reinforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'num_frames'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'smooth_reward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-6d492cef3196>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(args, parameter_update)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mexps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_experiences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mlogs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-de4f421233b5>\u001b[0m in \u001b[0;36mcollect_experiences\u001b[0;34m(env, acmodel, args, device)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mlog_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "args = Config()\n",
        "#args.max_episodes = args.max_episodes // 2 #delete later\n",
        "args.lr = 1e-4\n",
        "df = run_experiment(args, update_parameters_reinforce)\n",
        "df.plot(x='num_frames', y=['reward','smooth_reward'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-cVKxayYY1B"
      },
      "source": [
        "## REINFORCE with Discounted Reward\n",
        "\n",
        "Uh oh! Even after 300,000 steps, our policy does not converge. One reason for failure is the way rewards are generated in the real-world. In an ideal world, the agent would be rewarded at every timestep in a manner that perfectly corresponded to the quality of the action taken in a particular state.  However, this is rarely the case; for example, in Doorkey we only get reward at the very end of the episode (i.e., the sparse reward scenario).\n",
        "\n",
        "In DQN, we tackle this with a discount factor `gamma` on future rewards.  In policy gradients, we'll simply rewrite all of our step rewards to be discounted from the past episode reward.\n",
        "\n",
        "Fill in `compute_discounted_return` code block above, then run code cell below to see the effect of discounted reward trajectories.  This should converge, so if it doesn't, you've made an error (although try re-running the cell a few times first to make sure it's not a bad random seed). (10 pts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "4fDIhCpeZxdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "afdf17de491b4bb6b6778a53eea4c54f",
            "222d65b547464e7a84b9cd7d49557439",
            "e8bcfe08ef9c41c0a3a946640a35666d",
            "c08cf7f8b43a4f048003f085efd7eef8",
            "7581d038de574f74b6b695737b97f558",
            "0aa10e4ab1664aedb35813d78ff243c4",
            "14a5a3d8c21c4fcdb64980d59d0ddfd0",
            "21117013086046cca574e64bd5d12014",
            "76f67a8d101e4f00a544d7c4852a4b3e",
            "d73fcbc69ec54060bc34a94f8750c00e",
            "71a26333e87f4b6abaaf585242d856fb"
          ]
        },
        "outputId": "1da95733-373e-4606-9fcf-5d9e243f39dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afdf17de491b4bb6b6778a53eea4c54f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801, 0.3820, 0.3839,\n",
            "        0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996, 0.4016,\n",
            "        0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201,\n",
            "        0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395,\n",
            "        0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598,\n",
            "        0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633, 0.3651, 0.3670, 0.3688,\n",
            "        0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801, 0.3820, 0.3839, 0.3858,\n",
            "        0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996, 0.4016, 0.4036,\n",
            "        0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223,\n",
            "        0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417,\n",
            "        0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621,\n",
            "        0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834,\n",
            "        0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058,\n",
            "        0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291,\n",
            "        0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908,\n",
            "        0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462,\n",
            "        0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668,\n",
            "        0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883,\n",
            "        0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108,\n",
            "        0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344,\n",
            "        0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591,\n",
            "        0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849,\n",
            "        0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119,\n",
            "        0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159,\n",
            "        0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455, 0.3473,\n",
            "        0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633,\n",
            "        0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801,\n",
            "        0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976,\n",
            "        0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159,\n",
            "        0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3157, 0.3173, 0.3189, 0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286,\n",
            "        0.3303, 0.3320, 0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438,\n",
            "        0.3455, 0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597,\n",
            "        0.3615, 0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763,\n",
            "        0.3782, 0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936,\n",
            "        0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118,\n",
            "        0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308,\n",
            "        0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507,\n",
            "        0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644,\n",
            "        0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859,\n",
            "        0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083,\n",
            "        0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318,\n",
            "        0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563,\n",
            "        0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820,\n",
            "        0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088,\n",
            "        0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201,\n",
            "        0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395,\n",
            "        0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598,\n",
            "        0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159,\n",
            "        0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3455, 0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597,\n",
            "        0.3615, 0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763,\n",
            "        0.3782, 0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936,\n",
            "        0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118,\n",
            "        0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308,\n",
            "        0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507,\n",
            "        0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3763, 0.3782, 0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917,\n",
            "        0.3936, 0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097,\n",
            "        0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286,\n",
            "        0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484,\n",
            "        0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691,\n",
            "        0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908,\n",
            "        0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186,\n",
            "        0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425,\n",
            "        0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223,\n",
            "        0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417,\n",
            "        0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621,\n",
            "        0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834,\n",
            "        0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058,\n",
            "        0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291,\n",
            "        0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083,\n",
            "        0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318,\n",
            "        0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563,\n",
            "        0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820,\n",
            "        0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088,\n",
            "        0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291,\n",
            "        0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957,\n",
            "        0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186,\n",
            "        0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425,\n",
            "        0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3189, 0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286, 0.3303, 0.3320,\n",
            "        0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455, 0.3473,\n",
            "        0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633,\n",
            "        0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801,\n",
            "        0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976,\n",
            "        0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159,\n",
            "        0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3173, 0.3189, 0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286, 0.3303,\n",
            "        0.3320, 0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455,\n",
            "        0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615,\n",
            "        0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782,\n",
            "        0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956,\n",
            "        0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139,\n",
            "        0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330,\n",
            "        0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529,\n",
            "        0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738,\n",
            "        0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957,\n",
            "        0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186,\n",
            "        0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425,\n",
            "        0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644,\n",
            "        0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859,\n",
            "        0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083,\n",
            "        0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318,\n",
            "        0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563,\n",
            "        0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820,\n",
            "        0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088,\n",
            "        0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308,\n",
            "        0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507,\n",
            "        0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118,\n",
            "        0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308,\n",
            "        0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507,\n",
            "        0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057,\n",
            "        0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244,\n",
            "        0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440,\n",
            "        0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644,\n",
            "        0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859,\n",
            "        0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083,\n",
            "        0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318,\n",
            "        0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563,\n",
            "        0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820,\n",
            "        0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088,\n",
            "        0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3157, 0.3173, 0.3189, 0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286,\n",
            "        0.3303, 0.3320, 0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438,\n",
            "        0.3455, 0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597,\n",
            "        0.3615, 0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763,\n",
            "        0.3782, 0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936,\n",
            "        0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118,\n",
            "        0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308,\n",
            "        0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507,\n",
            "        0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.2929, 0.2943, 0.2958, 0.2973, 0.2988, 0.3003, 0.3018, 0.3033, 0.3048,\n",
            "        0.3064, 0.3079, 0.3095, 0.3110, 0.3126, 0.3141, 0.3157, 0.3173, 0.3189,\n",
            "        0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286, 0.3303, 0.3320, 0.3336,\n",
            "        0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455, 0.3473, 0.3490,\n",
            "        0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633, 0.3651,\n",
            "        0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801, 0.3820,\n",
            "        0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996,\n",
            "        0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180,\n",
            "        0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373,\n",
            "        0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575,\n",
            "        0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786,\n",
            "        0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007,\n",
            "        0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238,\n",
            "        0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480,\n",
            "        0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733,\n",
            "        0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997,\n",
            "        0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782,\n",
            "        0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956,\n",
            "        0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139,\n",
            "        0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330,\n",
            "        0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529,\n",
            "        0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738,\n",
            "        0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957,\n",
            "        0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186,\n",
            "        0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425,\n",
            "        0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007,\n",
            "        0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238,\n",
            "        0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480,\n",
            "        0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733,\n",
            "        0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997,\n",
            "        0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591,\n",
            "        0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849,\n",
            "        0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119,\n",
            "        0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834,\n",
            "        0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058,\n",
            "        0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291,\n",
            "        0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691,\n",
            "        0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908,\n",
            "        0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976,\n",
            "        0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159,\n",
            "        0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3421, 0.3438, 0.3455, 0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561,\n",
            "        0.3579, 0.3597, 0.3615, 0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725,\n",
            "        0.3744, 0.3763, 0.3782, 0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897,\n",
            "        0.3917, 0.3936, 0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077,\n",
            "        0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265,\n",
            "        0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462,\n",
            "        0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668,\n",
            "        0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883,\n",
            "        0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108,\n",
            "        0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344,\n",
            "        0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591,\n",
            "        0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849,\n",
            "        0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119,\n",
            "        0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733,\n",
            "        0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997,\n",
            "        0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480,\n",
            "        0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733,\n",
            "        0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997,\n",
            "        0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344,\n",
            "        0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591,\n",
            "        0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849,\n",
            "        0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119,\n",
            "        0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.2958, 0.2973, 0.2988, 0.3003, 0.3018, 0.3033, 0.3048, 0.3064, 0.3079,\n",
            "        0.3095, 0.3110, 0.3126, 0.3141, 0.3157, 0.3173, 0.3189, 0.3205, 0.3221,\n",
            "        0.3237, 0.3254, 0.3270, 0.3286, 0.3303, 0.3320, 0.3336, 0.3353, 0.3370,\n",
            "        0.3387, 0.3404, 0.3421, 0.3438, 0.3455, 0.3473, 0.3490, 0.3508, 0.3525,\n",
            "        0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633, 0.3651, 0.3670, 0.3688,\n",
            "        0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801, 0.3820, 0.3839, 0.3858,\n",
            "        0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996, 0.4016, 0.4036,\n",
            "        0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223,\n",
            "        0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417,\n",
            "        0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621,\n",
            "        0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834,\n",
            "        0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058,\n",
            "        0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291,\n",
            "        0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344,\n",
            "        0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591,\n",
            "        0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849,\n",
            "        0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119,\n",
            "        0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563,\n",
            "        0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820,\n",
            "        0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088,\n",
            "        0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3917, 0.3936, 0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077,\n",
            "        0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265,\n",
            "        0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462,\n",
            "        0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668,\n",
            "        0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883,\n",
            "        0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108,\n",
            "        0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344,\n",
            "        0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591,\n",
            "        0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849,\n",
            "        0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119,\n",
            "        0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575,\n",
            "        0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786,\n",
            "        0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007,\n",
            "        0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238,\n",
            "        0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480,\n",
            "        0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733,\n",
            "        0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997,\n",
            "        0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621,\n",
            "        0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834,\n",
            "        0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058,\n",
            "        0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291,\n",
            "        0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.3064, 0.3079, 0.3095, 0.3110, 0.3126, 0.3141, 0.3157, 0.3173, 0.3189,\n",
            "        0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286, 0.3303, 0.3320, 0.3336,\n",
            "        0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455, 0.3473, 0.3490,\n",
            "        0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633, 0.3651,\n",
            "        0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801, 0.3820,\n",
            "        0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996,\n",
            "        0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180,\n",
            "        0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373,\n",
            "        0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575,\n",
            "        0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786,\n",
            "        0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007,\n",
            "        0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238,\n",
            "        0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480,\n",
            "        0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733,\n",
            "        0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997,\n",
            "        0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849,\n",
            "        0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119,\n",
            "        0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976,\n",
            "        0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159,\n",
            "        0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223,\n",
            "        0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417,\n",
            "        0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621,\n",
            "        0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834,\n",
            "        0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058,\n",
            "        0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291,\n",
            "        0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782,\n",
            "        0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956,\n",
            "        0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139,\n",
            "        0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330,\n",
            "        0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529,\n",
            "        0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738,\n",
            "        0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957,\n",
            "        0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186,\n",
            "        0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425,\n",
            "        0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3286, 0.3303, 0.3320, 0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421,\n",
            "        0.3438, 0.3455, 0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579,\n",
            "        0.3597, 0.3615, 0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744,\n",
            "        0.3763, 0.3782, 0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917,\n",
            "        0.3936, 0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097,\n",
            "        0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286,\n",
            "        0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484,\n",
            "        0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691,\n",
            "        0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908,\n",
            "        0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976,\n",
            "        0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159,\n",
            "        0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.2885, 0.2899, 0.2914, 0.2929, 0.2943, 0.2958, 0.2973, 0.2988, 0.3003,\n",
            "        0.3018, 0.3033, 0.3048, 0.3064, 0.3079, 0.3095, 0.3110, 0.3126, 0.3141,\n",
            "        0.3157, 0.3173, 0.3189, 0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286,\n",
            "        0.3303, 0.3320, 0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438,\n",
            "        0.3455, 0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597,\n",
            "        0.3615, 0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763,\n",
            "        0.3782, 0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936,\n",
            "        0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118,\n",
            "        0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308,\n",
            "        0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507,\n",
            "        0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3320, 0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455,\n",
            "        0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615,\n",
            "        0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782,\n",
            "        0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956,\n",
            "        0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139,\n",
            "        0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330,\n",
            "        0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529,\n",
            "        0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738,\n",
            "        0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957,\n",
            "        0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186,\n",
            "        0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425,\n",
            "        0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3254, 0.3270, 0.3286, 0.3303, 0.3320, 0.3336, 0.3353, 0.3370, 0.3387,\n",
            "        0.3404, 0.3421, 0.3438, 0.3455, 0.3473, 0.3490, 0.3508, 0.3525, 0.3543,\n",
            "        0.3561, 0.3579, 0.3597, 0.3615, 0.3633, 0.3651, 0.3670, 0.3688, 0.3707,\n",
            "        0.3725, 0.3744, 0.3763, 0.3782, 0.3801, 0.3820, 0.3839, 0.3858, 0.3878,\n",
            "        0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057,\n",
            "        0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244,\n",
            "        0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440,\n",
            "        0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644,\n",
            "        0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859,\n",
            "        0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083,\n",
            "        0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318,\n",
            "        0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563,\n",
            "        0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820,\n",
            "        0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088,\n",
            "        0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3189, 0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286, 0.3303, 0.3320,\n",
            "        0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455, 0.3473,\n",
            "        0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633,\n",
            "        0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801,\n",
            "        0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976,\n",
            "        0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159,\n",
            "        0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351,\n",
            "        0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3033, 0.3048, 0.3064, 0.3079, 0.3095, 0.3110, 0.3126, 0.3141, 0.3157,\n",
            "        0.3173, 0.3189, 0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286, 0.3303,\n",
            "        0.3320, 0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455,\n",
            "        0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615,\n",
            "        0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782,\n",
            "        0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956,\n",
            "        0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139,\n",
            "        0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330,\n",
            "        0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529,\n",
            "        0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738,\n",
            "        0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957,\n",
            "        0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186,\n",
            "        0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425,\n",
            "        0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615,\n",
            "        0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782,\n",
            "        0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956,\n",
            "        0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139,\n",
            "        0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330,\n",
            "        0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529,\n",
            "        0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738,\n",
            "        0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957,\n",
            "        0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186,\n",
            "        0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425,\n",
            "        0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318,\n",
            "        0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563,\n",
            "        0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820,\n",
            "        0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088,\n",
            "        0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908,\n",
            "        0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996, 0.4016,\n",
            "        0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201,\n",
            "        0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395,\n",
            "        0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598,\n",
            "        0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.2929, 0.2943, 0.2958, 0.2973, 0.2988, 0.3003, 0.3018, 0.3033, 0.3048,\n",
            "        0.3064, 0.3079, 0.3095, 0.3110, 0.3126, 0.3141, 0.3157, 0.3173, 0.3189,\n",
            "        0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286, 0.3303, 0.3320, 0.3336,\n",
            "        0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455, 0.3473, 0.3490,\n",
            "        0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633, 0.3651,\n",
            "        0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801, 0.3820,\n",
            "        0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996,\n",
            "        0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180,\n",
            "        0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373,\n",
            "        0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575,\n",
            "        0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786,\n",
            "        0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007,\n",
            "        0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238,\n",
            "        0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480,\n",
            "        0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733,\n",
            "        0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997,\n",
            "        0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4118, 0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286,\n",
            "        0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484,\n",
            "        0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691,\n",
            "        0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908,\n",
            "        0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691,\n",
            "        0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908,\n",
            "        0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598,\n",
            "        0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480,\n",
            "        0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733,\n",
            "        0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997,\n",
            "        0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4308, 0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484,\n",
            "        0.4507, 0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691,\n",
            "        0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908,\n",
            "        0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507,\n",
            "        0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201,\n",
            "        0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395,\n",
            "        0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598,\n",
            "        0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119,\n",
            "        0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401,\n",
            "        0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696,\n",
            "        0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005,\n",
            "        0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3079, 0.3095, 0.3110, 0.3126, 0.3141, 0.3157, 0.3173, 0.3189, 0.3205,\n",
            "        0.3221, 0.3237, 0.3254, 0.3270, 0.3286, 0.3303, 0.3320, 0.3336, 0.3353,\n",
            "        0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455, 0.3473, 0.3490, 0.3508,\n",
            "        0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633, 0.3651, 0.3670,\n",
            "        0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801, 0.3820, 0.3839,\n",
            "        0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996, 0.4016,\n",
            "        0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180, 0.4201,\n",
            "        0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373, 0.4395,\n",
            "        0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575, 0.4598,\n",
            "        0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318,\n",
            "        0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563,\n",
            "        0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820,\n",
            "        0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088,\n",
            "        0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552,\n",
            "        0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762,\n",
            "        0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982,\n",
            "        0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "discounted reward:  tensor([0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318,\n",
            "        0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563,\n",
            "        0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820,\n",
            "        0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088,\n",
            "        0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369,\n",
            "        0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663,\n",
            "        0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970,\n",
            "        0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810,\n",
            "        0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3157, 0.3173, 0.3189, 0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286,\n",
            "        0.3303, 0.3320, 0.3336, 0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438,\n",
            "        0.3455, 0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597,\n",
            "        0.3615, 0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763,\n",
            "        0.3782, 0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936,\n",
            "        0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118,\n",
            "        0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308,\n",
            "        0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507,\n",
            "        0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908,\n",
            "        0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134,\n",
            "        0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371,\n",
            "        0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619,\n",
            "        0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032,\n",
            "        0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264,\n",
            "        0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507,\n",
            "        0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762,\n",
            "        0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878,\n",
            "        0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149,\n",
            "        0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3064, 0.3079, 0.3095, 0.3110, 0.3126, 0.3141, 0.3157, 0.3173, 0.3189,\n",
            "        0.3205, 0.3221, 0.3237, 0.3254, 0.3270, 0.3286, 0.3303, 0.3320, 0.3336,\n",
            "        0.3353, 0.3370, 0.3387, 0.3404, 0.3421, 0.3438, 0.3455, 0.3473, 0.3490,\n",
            "        0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615, 0.3633, 0.3651,\n",
            "        0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782, 0.3801, 0.3820,\n",
            "        0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956, 0.3976, 0.3996,\n",
            "        0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139, 0.4159, 0.4180,\n",
            "        0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330, 0.4351, 0.4373,\n",
            "        0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529, 0.4552, 0.4575,\n",
            "        0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786,\n",
            "        0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007,\n",
            "        0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238,\n",
            "        0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480,\n",
            "        0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733,\n",
            "        0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997,\n",
            "        0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274,\n",
            "        0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564,\n",
            "        0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866,\n",
            "        0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183,\n",
            "        0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515,\n",
            "        0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.4644, 0.4668, 0.4691, 0.4715, 0.4738, 0.4762, 0.4786, 0.4810, 0.4834,\n",
            "        0.4859, 0.4883, 0.4908, 0.4932, 0.4957, 0.4982, 0.5007, 0.5032, 0.5058,\n",
            "        0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212, 0.5238, 0.5264, 0.5291,\n",
            "        0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452, 0.5480, 0.5507, 0.5535,\n",
            "        0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704, 0.5733, 0.5762, 0.5790,\n",
            "        0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027, 0.6058,\n",
            "        0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337,\n",
            "        0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630,\n",
            "        0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936,\n",
            "        0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256,\n",
            "        0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590,\n",
            "        0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941,\n",
            "        0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307,\n",
            "        0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691,\n",
            "        0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092,\n",
            "        0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511,\n",
            "        0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950,\n",
            "        1.0000])\n",
            "discounted reward:  tensor([0.3473, 0.3490, 0.3508, 0.3525, 0.3543, 0.3561, 0.3579, 0.3597, 0.3615,\n",
            "        0.3633, 0.3651, 0.3670, 0.3688, 0.3707, 0.3725, 0.3744, 0.3763, 0.3782,\n",
            "        0.3801, 0.3820, 0.3839, 0.3858, 0.3878, 0.3897, 0.3917, 0.3936, 0.3956,\n",
            "        0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118, 0.4139,\n",
            "        0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308, 0.4330,\n",
            "        0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507, 0.4529,\n",
            "        0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715, 0.4738,\n",
            "        0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932, 0.4957,\n",
            "        0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186,\n",
            "        0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425,\n",
            "        0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676,\n",
            "        0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937,\n",
            "        0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211,\n",
            "        0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498,\n",
            "        0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798,\n",
            "        0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112,\n",
            "        0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862,\n",
            "        0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224,\n",
            "        0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604,\n",
            "        0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001,\n",
            "        0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416,\n",
            "        0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851,\n",
            "        0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292,\n",
            "        0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629,\n",
            "        0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981,\n",
            "        0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329,\n",
            "        0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667,\n",
            "        0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021,\n",
            "        0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349,\n",
            "        0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734,\n",
            "        0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137,\n",
            "        0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559,\n",
            "        0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.6180, 0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433,\n",
            "        0.6466, 0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730,\n",
            "        0.6764, 0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041,\n",
            "        0.7076, 0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366,\n",
            "        0.7403, 0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705,\n",
            "        0.7744, 0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061,\n",
            "        0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433,\n",
            "        0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.3956, 0.3976, 0.3996, 0.4016, 0.4036, 0.4057, 0.4077, 0.4097, 0.4118,\n",
            "        0.4139, 0.4159, 0.4180, 0.4201, 0.4223, 0.4244, 0.4265, 0.4286, 0.4308,\n",
            "        0.4330, 0.4351, 0.4373, 0.4395, 0.4417, 0.4440, 0.4462, 0.4484, 0.4507,\n",
            "        0.4529, 0.4552, 0.4575, 0.4598, 0.4621, 0.4644, 0.4668, 0.4691, 0.4715,\n",
            "        0.4738, 0.4762, 0.4786, 0.4810, 0.4834, 0.4859, 0.4883, 0.4908, 0.4932,\n",
            "        0.4957, 0.4982, 0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160,\n",
            "        0.5186, 0.5212, 0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398,\n",
            "        0.5425, 0.5452, 0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647,\n",
            "        0.5676, 0.5704, 0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908,\n",
            "        0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967, 0.5997, 0.6027,\n",
            "        0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243, 0.6274, 0.6306,\n",
            "        0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531, 0.6564, 0.6597,\n",
            "        0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832, 0.6866, 0.6901,\n",
            "        0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147, 0.7183, 0.7219,\n",
            "        0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477, 0.7515, 0.7553,\n",
            "        0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822, 0.7862, 0.7901,\n",
            "        0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266,\n",
            "        0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647,\n",
            "        0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046,\n",
            "        0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464,\n",
            "        0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900,\n",
            "        0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5937, 0.5967, 0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180,\n",
            "        0.6211, 0.6243, 0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466,\n",
            "        0.6498, 0.6531, 0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764,\n",
            "        0.6798, 0.6832, 0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076,\n",
            "        0.7112, 0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403,\n",
            "        0.7440, 0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744,\n",
            "        0.7783, 0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102,\n",
            "        0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475,\n",
            "        0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867,\n",
            "        0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276,\n",
            "        0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704,\n",
            "        0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.5007, 0.5032, 0.5058, 0.5083, 0.5108, 0.5134, 0.5160, 0.5186, 0.5212,\n",
            "        0.5238, 0.5264, 0.5291, 0.5318, 0.5344, 0.5371, 0.5398, 0.5425, 0.5452,\n",
            "        0.5480, 0.5507, 0.5535, 0.5563, 0.5591, 0.5619, 0.5647, 0.5676, 0.5704,\n",
            "        0.5733, 0.5762, 0.5790, 0.5820, 0.5849, 0.5878, 0.5908, 0.5937, 0.5967,\n",
            "        0.5997, 0.6027, 0.6058, 0.6088, 0.6119, 0.6149, 0.6180, 0.6211, 0.6243,\n",
            "        0.6274, 0.6306, 0.6337, 0.6369, 0.6401, 0.6433, 0.6466, 0.6498, 0.6531,\n",
            "        0.6564, 0.6597, 0.6630, 0.6663, 0.6696, 0.6730, 0.6764, 0.6798, 0.6832,\n",
            "        0.6866, 0.6901, 0.6936, 0.6970, 0.7005, 0.7041, 0.7076, 0.7112, 0.7147,\n",
            "        0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440, 0.7477,\n",
            "        0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783, 0.7822,\n",
            "        0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142, 0.8183,\n",
            "        0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518, 0.8561,\n",
            "        0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911, 0.8956,\n",
            "        0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322, 0.9369,\n",
            "        0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752, 0.9801,\n",
            "        0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.7147, 0.7183, 0.7219, 0.7256, 0.7292, 0.7329, 0.7366, 0.7403, 0.7440,\n",
            "        0.7477, 0.7515, 0.7553, 0.7590, 0.7629, 0.7667, 0.7705, 0.7744, 0.7783,\n",
            "        0.7822, 0.7862, 0.7901, 0.7941, 0.7981, 0.8021, 0.8061, 0.8102, 0.8142,\n",
            "        0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391, 0.8433, 0.8475, 0.8518,\n",
            "        0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822, 0.8867, 0.8911,\n",
            "        0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229, 0.9276, 0.9322,\n",
            "        0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655, 0.9704, 0.9752,\n",
            "        0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8061, 0.8102, 0.8142, 0.8183, 0.8224, 0.8266, 0.8307, 0.8349, 0.8391,\n",
            "        0.8433, 0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778,\n",
            "        0.8822, 0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183,\n",
            "        0.9229, 0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607,\n",
            "        0.9655, 0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "discounted reward:  tensor([0.8475, 0.8518, 0.8561, 0.8604, 0.8647, 0.8691, 0.8734, 0.8778, 0.8822,\n",
            "        0.8867, 0.8911, 0.8956, 0.9001, 0.9046, 0.9092, 0.9137, 0.9183, 0.9229,\n",
            "        0.9276, 0.9322, 0.9369, 0.9416, 0.9464, 0.9511, 0.9559, 0.9607, 0.9655,\n",
            "        0.9704, 0.9752, 0.9801, 0.9851, 0.9900, 0.9950, 1.0000])\n",
            "Solved!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f76e28f74d0>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args = Config(use_discounted_reward=True)\n",
        "args.max_episodes = args.max_episodes // 2 #delete later\n",
        "df = run_experiment(args, update_parameters_reinforce)\n",
        "df.plot(x='num_frames', y=['reward', 'smooth_reward'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lWHQpkubqpM"
      },
      "source": [
        "# Vanilla Policy Gradients\n",
        "\n",
        "You may have noticed that the REINFORCE training curve is extremely unstable. It's time to bring in our *critic*!  We can prove from the Expected Grad-Log-Prob (EGLP) lemma that we can subtract any function $b(x)$ from our reward without changing our policy in expectation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8PdtlQTbDdg"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OSRQMGGqfUj"
      },
      "source": [
        "### Baseline Proof\n",
        "\n",
        "**Question**: Prove that adding a baseline doesn't change the policy in expectation using the EGLP lemma.  This can be a loose proof as long as you convey the intutition. (10 pts)\n",
        "\n",
        "**Proof**: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXJ4XqNbs0n"
      },
      "source": [
        "Empirically, using the on-policy value function as the baseline ($b$) reduces variance in the policy gradient sample estimate, leading to faster and more stable learning.  We can estimate the $b$ using an L2 loss to the true rewards (or in our case, the discounted rewards), and constitutes an additional loss term in the overall objective. The baseline substracted return term, $R(s_{t'},a_{t'},s_{t' + 1}) - b(s_t)$ is already computed for you, and is referred to as the *advantage*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM4Rqfe9bDdi"
      },
      "outputs": [],
      "source": [
        "def update_parameters_with_baseline(optimizer, acmodel, sb, args):\n",
        "    def _compute_policy_loss_with_baseline(logps, advantages):\n",
        "        policy_loss = 0\n",
        "\n",
        "        ### TODO: implement the policy loss (5 pts) ##############\n",
        "\n",
        "        ##################################################\n",
        "        \n",
        "        return policy_loss\n",
        "    \n",
        "    def _compute_value_loss(values, returns):\n",
        "        value_loss = 0\n",
        "\n",
        "        ### TODO: implement the value loss (5 pts) ###############\n",
        "\n",
        "        ##################################################\n",
        "\n",
        "        return value_loss\n",
        "\n",
        "    logps, advantage, values, reward = None, None, None, None\n",
        "\n",
        "    ### TODO: populate the policy and value loss computation fields using acmodel, sb['obs'], sb['action], and sb['discounted_reward']\n",
        "    ### For the advantage term, use sb['advantage_gae'] if args.use_gae is True, and sb['advantage'] otherwise.\n",
        "    ### 10 pts\n",
        "\n",
        "    ####################################################################################################\n",
        "\n",
        "    policy_loss = _compute_policy_loss_with_baseline(logps, advantage)\n",
        "    value_loss = _compute_value_loss(values, reward)\n",
        "    loss = policy_loss + value_loss\n",
        "\n",
        "    update_policy_loss = policy_loss.item()\n",
        "    update_value_loss = value_loss.item()\n",
        "\n",
        "    # Update actor-critic\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    update_grad_norm = sum(p.grad.data.norm(2) ** 2 for p in acmodel.parameters()) ** 0.5\n",
        "    torch.nn.utils.clip_grad_norm_(acmodel.parameters(), args.max_grad_norm)\n",
        "    optimizer.step()\n",
        "\n",
        "    # Log some values\n",
        "\n",
        "    logs = {\n",
        "        \"policy_loss\": update_policy_loss,\n",
        "        \"value_loss\": update_value_loss,\n",
        "        \"grad_norm\": update_grad_norm\n",
        "    }\n",
        "\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcftj9PpbDdi"
      },
      "source": [
        "## Run REINFORCE with baseline\n",
        "\n",
        "If you did everything right, you should be able to run the below cell to run the vanilla policy gradients implementation with baseline.  This should be somewhat more stable than without the baseline, and likely converge faster.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygISg6VJbDdi"
      },
      "outputs": [],
      "source": [
        "args = Config(use_critic=True)\n",
        "df_baseline = run_experiment(args, update_parameters_with_baseline)\n",
        "\n",
        "df_baseline.plot(x='num_frames', y=['reward', 'smooth_reward'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfHluYAfTKC"
      },
      "source": [
        "# Reinforce with GAE\n",
        "\n",
        "The advantage we computed above seemed to work, and hopefully improved our results!  Fortunately, we can do even better.  The paper [Generalized Advantage Estimation](https://arxiv.org/abs/1506.02438) describes a nifty method for building a strong advantage estimate (see formula 16 in the paper) that empirically outperforms a naive subtraction (and includes reward shaping).\n",
        "\n",
        "Fill in the `compute_advantage_gae` method above according to the formula in the paper (10 pts), and then run the below cell.  GAE should further improve convergence time and stability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcfHPVV5JmGb"
      },
      "outputs": [],
      "source": [
        "args = Config(use_critic=True, use_gae=True)\n",
        "df_gae = run_experiment(args, update_parameters_with_baseline)\n",
        "\n",
        "df_gae.plot(x='num_frames', y=['reward', 'smooth_reward'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BoRwiFabDdi"
      },
      "source": [
        "# Proximal Policy Optimization\n",
        "\n",
        "Our work is not yet done!  There are some surprisingly powerful additional tweaks we can make to our GAE implementation to further improve performance.\n",
        "\n",
        "The current standard in policy gradients today is [Proximal Policy Optimization](https://arxiv.org/abs/1707.06347), which improves on GAE by taking multiply policy update steps per minibatch, enabled by policy update clipping (this is a specific variant called *PPO-Clip*).  This leads to greater sample efficiency, as larger steps can be taken from the same data samples.\n",
        "\n",
        "We've implemented most of PPO for you: all that's left for you are the policy and value loss computations (note that you'll have to evaluate the `acmodel` each time you compute them).  Note that for the policy loss, we also ask that you return the approximate KL divergence between the new and old action distributions notated as `approx_kl`; this is used to facilitate an early stopping condition in policy updates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFLxFbVwkBrk"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb84WAVpbDdi"
      },
      "outputs": [],
      "source": [
        "def update_parameters_ppo(optimizer, acmodel, sb, args):\n",
        "    def _compute_policy_loss_ppo(obs, old_logp, actions, advantages):\n",
        "        policy_loss, approx_kl = 0, 0\n",
        "\n",
        "        ### TODO: implement PPO policy loss computation (30 pts).  #######\n",
        "\n",
        "        ##################################################################\n",
        "        \n",
        "        return policy_loss, approx_kl\n",
        "    \n",
        "    def _compute_value_loss(obs, returns):\n",
        "        ### TODO: implement PPO value loss computation (10 pts) ##########\n",
        "\n",
        "        ##################################################################\n",
        "\n",
        "        return value_loss\n",
        "\n",
        "\n",
        "    dist, _ = acmodel(sb['obs'])            \n",
        "    old_logp = dist.log_prob(sb['action']).detach()\n",
        "    \n",
        "    advantage = sb['advantage_gae'] if args.use_gae else sb['advantage']\n",
        "\n",
        "    policy_loss, _ = _compute_policy_loss_ppo(sb['obs'], old_logp, sb['action'], advantage)\n",
        "    value_loss = _compute_value_loss(sb['obs'], sb['discounted_reward'])\n",
        "\n",
        "    for i in range(args.train_ac_iters):\n",
        "        optimizer.zero_grad()\n",
        "        loss_pi, approx_kl = _compute_policy_loss_ppo(sb['obs'], old_logp, sb['action'], advantage)\n",
        "        loss_v = _compute_value_loss(sb['obs'], sb['discounted_reward'])\n",
        "\n",
        "        loss = loss_v + loss_pi\n",
        "        if approx_kl > 1.5 * args.target_kl:\n",
        "            break\n",
        "        \n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "    \n",
        "    update_policy_loss = policy_loss.item()\n",
        "    update_value_loss = value_loss.item()\n",
        "\n",
        "    logs = {\n",
        "        \"policy_loss\": update_policy_loss,\n",
        "        \"value_loss\": update_value_loss,\n",
        "    }\n",
        "\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElBRzBVdbDdj",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "args = Config(use_critic=True, use_gae=True)\n",
        "df_ppo = run_experiment(args, update_parameters_ppo)\n",
        "\n",
        "df_ppo.plot(x='num_frames', y=['reward', 'smooth_reward'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC25PuG1oE0z"
      },
      "source": [
        "# Fancy Plots\n",
        "\n",
        "If you've gotten to this point, congrats: you've succesfully implemented REINFORCE, VPG, GAE, and PPO!  While we've been able to anecdotally compare their performance, we don't have any sense of *scientific rigor*.  Notably, given the variance you've likely seen between runs of these models, a single run may not reflect how strong a model really is.\n",
        "\n",
        "For this problem, train each of these 4 methods using multiple seeds (at least 5, but more if you feel you need them).  Then, generate a high quality reward curve plot comparing each algorithm.  The plot should be clean and legible, and clearly demonstrate the performance and variance of each of the approaches.  As an example, see Figure 3 of the PPO paper (although we're only evaluating on a single environment).\n",
        "\n",
        "Be creative and make something pretty: it matters for good science!\n",
        "\n",
        "**Note:** you should leave a few hours for this to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXgEr5bDpCB6"
      },
      "outputs": [],
      "source": [
        "### TODO: generate your master comparison plot (30 pts)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "policygradients",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "32d70935683b4b70ba52ce4d8c4ecf31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba4adfef044e4cbb9f9a743b86c596ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc28ede2352e4a0989d740aeb9a57ba9",
              "IPY_MODEL_984bc6afff304445a5a3c1047e9104af",
              "IPY_MODEL_e03872966c434462861b46c3b29393a2"
            ]
          }
        },
        "ba4adfef044e4cbb9f9a743b86c596ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc28ede2352e4a0989d740aeb9a57ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_26f74b809e254d02a380a3c94c7b24fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  1%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b53b994be6b342ccaac24cadbd274e6c"
          }
        },
        "984bc6afff304445a5a3c1047e9104af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a8f4f5a33564cb5b5de647df27da9e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de4f8894d42548fdae361e0f9e574369"
          }
        },
        "e03872966c434462861b46c3b29393a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e46cce569d5647cdb6e0c7b9eb7f1e62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25/2000 [00:22&lt;30:43,  1.07it/s, episode=24, num_frames=6054, smooth_reward=0.04, reward=0, policy_loss=-]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba875c6c447446c695b15cb23f5378ea"
          }
        },
        "26f74b809e254d02a380a3c94c7b24fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b53b994be6b342ccaac24cadbd274e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a8f4f5a33564cb5b5de647df27da9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de4f8894d42548fdae361e0f9e574369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e46cce569d5647cdb6e0c7b9eb7f1e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba875c6c447446c695b15cb23f5378ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afdf17de491b4bb6b6778a53eea4c54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_222d65b547464e7a84b9cd7d49557439",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e8bcfe08ef9c41c0a3a946640a35666d",
              "IPY_MODEL_c08cf7f8b43a4f048003f085efd7eef8",
              "IPY_MODEL_7581d038de574f74b6b695737b97f558"
            ]
          }
        },
        "222d65b547464e7a84b9cd7d49557439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8bcfe08ef9c41c0a3a946640a35666d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0aa10e4ab1664aedb35813d78ff243c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14a5a3d8c21c4fcdb64980d59d0ddfd0"
          }
        },
        "c08cf7f8b43a4f048003f085efd7eef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21117013086046cca574e64bd5d12014",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76f67a8d101e4f00a544d7c4852a4b3e"
          }
        },
        "7581d038de574f74b6b695737b97f558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d73fcbc69ec54060bc34a94f8750c00e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 437/1000 [04:51&lt;01:56,  4.84it/s, episode=437, num_frames=84382, smooth_reward=0.94, reward=1, policy_loss=39.9]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71a26333e87f4b6abaaf585242d856fb"
          }
        },
        "0aa10e4ab1664aedb35813d78ff243c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14a5a3d8c21c4fcdb64980d59d0ddfd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21117013086046cca574e64bd5d12014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76f67a8d101e4f00a544d7c4852a4b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d73fcbc69ec54060bc34a94f8750c00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71a26333e87f4b6abaaf585242d856fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}